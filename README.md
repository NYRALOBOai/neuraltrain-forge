# NeuralTrain Forge ğŸ§ 

Uma aplicaÃ§Ã£o web completa e profissional para fine-tuning de modelos de linguagem (LLMs) com suporte a LoRA, QLoRA, PEFT e integraÃ§Ã£o com HuggingFace Hub.

![NeuralTrain Forge](https://img.shields.io/badge/NeuralTrain%20Forge-v1.0.0-blue)
![Python](https://img.shields.io/badge/Python-3.10+-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.45+-red)
![License](https://img.shields.io/badge/License-MIT-yellow)

## ğŸ¯ VisÃ£o Geral

O NeuralTrain Forge Ã© uma plataforma web moderna e intuitiva desenvolvida especificamente para facilitar o fine-tuning de modelos de linguagem. A aplicaÃ§Ã£o oferece uma interface grÃ¡fica completa que permite aos desenvolvedores e pesquisadores de IA treinar modelos de forma eficiente, segura e escalÃ¡vel.

### âœ¨ CaracterÃ­sticas Principais

- **Interface Web Moderna**: Interface desenvolvida com Streamlit, responsiva e intuitiva
- **Suporte Completo a LoRA/QLoRA**: ImplementaÃ§Ã£o otimizada para fine-tuning eficiente
- **IntegraÃ§Ã£o HuggingFace**: Download e upload direto de modelos do HuggingFace Hub
- **MÃºltiplos Formatos**: Suporte a .gguf, .bin, .safetensors e outros formatos
- **Monitoramento em Tempo Real**: Acompanhamento de mÃ©tricas e progresso durante o treinamento
- **VisualizaÃ§Ãµes AvanÃ§adas**: GrÃ¡ficos interativos com Plotly para anÃ¡lise de resultados
- **Arquitetura Modular**: CÃ³digo organizado e extensÃ­vel para futuras melhorias
- **Compatibilidade Cloud**: Otimizado para Paperspace, RunPod e outras plataformas

## ğŸš€ InstalaÃ§Ã£o RÃ¡pida

### PrÃ©-requisitos

- Python 3.10 ou superior
- CUDA 11.8+ (opcional, para aceleraÃ§Ã£o GPU)
- 8GB+ RAM (16GB+ recomendado)
- 50GB+ espaÃ§o em disco

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/seu-usuario/neuraltrain-forge.git
cd neuraltrain-forge
```

2. **Crie e ative o ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Execute a aplicaÃ§Ã£o:**
```bash
streamlit run main.py
```

5. **Acesse no navegador:**
```
http://localhost:8501
```

## ğŸ“‹ Funcionalidades Detalhadas

### ğŸ  Dashboard Principal

O dashboard oferece uma visÃ£o geral completa do sistema:

- **MÃ©tricas em Tempo Real**: Modelos carregados, datasets disponÃ­veis, jobs ativos
- **EstatÃ­sticas de Treinamento**: Progresso, tempo estimado, precisÃ£o
- **GrÃ¡ficos Interativos**: VisualizaÃ§Ã£o de tendÃªncias e performance
- **Status do Sistema**: Monitoramento de recursos (GPU, RAM, armazenamento)

### ğŸ“¤ Upload de Modelos

Sistema completo para gerenciamento de modelos:

#### Upload Local
- Suporte a mÃºltiplos formatos: `.gguf`, `.bin`, `.safetensors`, `.pt`
- ValidaÃ§Ã£o automÃ¡tica de integridade
- DetecÃ§Ã£o de arquitetura e parÃ¢metros
- Limite de 200MB por arquivo (configurÃ¡vel)

#### HuggingFace Hub
- Busca e download direto de modelos
- AutenticaÃ§Ã£o com token HF
- Cache inteligente para otimizaÃ§Ã£o
- Suporte a modelos privados

#### Modelos Carregados
- Lista organizada de modelos disponÃ­veis
- InformaÃ§Ãµes detalhadas (tamanho, tipo, data)
- Funcionalidades de ediÃ§Ã£o e remoÃ§Ã£o
- Sistema de tags e categorizaÃ§Ã£o

### ğŸ“Š Upload de Datasets

Gerenciamento avanÃ§ado de datasets para treinamento:

#### Formatos Suportados
- **Texto Simples** (`.txt`): Para treinamento de linguagem
- **JSONL** (`.jsonl`): Formato estruturado para conversaÃ§Ãµes
- **CSV** (`.csv`): Dados tabulares com colunas personalizÃ¡veis
- **Parquet** (`.parquet`): Formato otimizado para grandes volumes

#### Processamento AutomÃ¡tico
- ValidaÃ§Ã£o de formato e estrutura
- EstatÃ­sticas automÃ¡ticas (tokens, linhas, tamanho)
- PrÃ©-visualizaÃ§Ã£o dos dados
- DivisÃ£o automÃ¡tica treino/validaÃ§Ã£o

#### ConfiguraÃ§Ãµes AvanÃ§adas
- TokenizaÃ§Ã£o personalizada
- Filtros de qualidade
- Balanceamento de classes
- AugmentaÃ§Ã£o de dados

### âš™ï¸ ConfiguraÃ§Ã£o de Treinamento

Interface completa para configuraÃ§Ã£o de fine-tuning:

#### ConfiguraÃ§Ãµes BÃ¡sicas
- **Nome do Job**: IdentificaÃ§Ã£o Ãºnica do treinamento
- **Modelo Base**: SeleÃ§Ã£o do modelo para fine-tuning
- **Dataset**: Escolha do dataset de treinamento
- **Tipo de Treinamento**: LoRA, QLoRA ou Full Fine-tuning

#### ConfiguraÃ§Ãµes LoRA/QLoRA
- **Rank (r)**: Controle da complexidade dos adaptadores (1-256)
- **Alpha**: Fator de escala para estabilidade (1-512)
- **Dropout**: RegularizaÃ§Ã£o para evitar overfitting (0.0-0.5)
- **Target Modules**: SeleÃ§Ã£o de camadas para adaptaÃ§Ã£o
- **Bias**: ConfiguraÃ§Ã£o de tratamento de bias

#### ParÃ¢metros de Treinamento
- **Ã‰pocas**: NÃºmero de passadas pelos dados (1-100)
- **Learning Rate**: Taxa de aprendizado (1e-6 a 1e-2)
- **Batch Size**: Tamanho do lote (1, 2, 4, 8, 16, 32)
- **Gradient Accumulation**: AcumulaÃ§Ã£o de gradientes (1-32)
- **Max Length**: Comprimento mÃ¡ximo de sequÃªncia (128-4096)
- **Warmup Ratio**: ProporÃ§Ã£o de aquecimento (0.0-0.2)

#### ConfiguraÃ§Ãµes AvanÃ§adas
- **Otimizador**: AdamW, SGD, AdamW HF
- **Scheduler**: Linear, Cosine, Polynomial
- **Weight Decay**: RegularizaÃ§Ã£o L2
- **FP16/BF16**: PrecisÃ£o mista para otimizaÃ§Ã£o
- **Gradient Checkpointing**: Economia de memÃ³ria
- **DataLoader Workers**: ParalelizaÃ§Ã£o de carregamento

#### ConfiguraÃ§Ãµes de Salvamento
- **EstratÃ©gia**: Por passos, por Ã©poca ou desabilitado
- **Intervalo**: FrequÃªncia de salvamento
- **Limite de Checkpoints**: NÃºmero mÃ¡ximo mantido
- **Melhor Modelo**: Carregamento automÃ¡tico do melhor resultado

#### ConfiguraÃ§Ãµes de Logging
- **FrequÃªncia**: Intervalo de logging de mÃ©tricas
- **AvaliaÃ§Ã£o**: EstratÃ©gia de validaÃ§Ã£o
- **RelatÃ³rios**: TensorBoard, Weights & Biases
- **MÃ©tricas Customizadas**: DefiniÃ§Ã£o de mÃ©tricas especÃ­ficas

### ğŸ“ˆ Resultados e AnÃ¡lise

Sistema completo de visualizaÃ§Ã£o e anÃ¡lise de resultados:

#### Dashboard de Resultados
- **MÃ©tricas Resumidas**: Treinamentos concluÃ­dos, melhor loss, tempo mÃ©dio
- **GrÃ¡ficos de TendÃªncia**: EvoluÃ§Ã£o temporal dos treinamentos
- **ComparaÃ§Ã£o de Modelos**: AnÃ¡lise comparativa de performance
- **Rankings**: ClassificaÃ§Ã£o por performance e mÃ©tricas

#### AnÃ¡lise Detalhada
- **Curvas de Loss**: VisualizaÃ§Ã£o de treino e validaÃ§Ã£o
- **Learning Rate Schedule**: EvoluÃ§Ã£o da taxa de aprendizado
- **MÃ©tricas de Treinamento**: Loss, perplexidade, gradient norm
- **MÃ©tricas de AvaliaÃ§Ã£o**: BLEU, ROUGE, accuracy, F1-score

#### Modelos Treinados
- **Lista Organizada**: Todos os modelos com filtros avanÃ§ados
- **InformaÃ§Ãµes Detalhadas**: ConfiguraÃ§Ãµes, mÃ©tricas, metadados
- **AÃ§Ãµes DisponÃ­veis**: Testar, baixar, arquivar, compartilhar
- **Sistema de Versionamento**: Controle de versÃµes dos modelos

#### Downloads e ExportaÃ§Ã£o
- **Modelos**: Download em mÃºltiplos formatos
- **RelatÃ³rios**: PDF completo, CSV de mÃ©tricas, configuraÃ§Ãµes JSON
- **Dados de Treinamento**: ExportaÃ§Ã£o de logs e mÃ©tricas
- **Checkpoints**: Acesso a pontos intermediÃ¡rios

## ğŸ—ï¸ Arquitetura TÃ©cnica

### Estrutura do Projeto

```
neuraltrain-forge/
â”œâ”€â”€ main.py                 # Ponto de entrada da aplicaÃ§Ã£o
â”œâ”€â”€ requirements.txt        # DependÃªncias Python
â”œâ”€â”€ Dockerfile             # ContainerizaÃ§Ã£o
â”œâ”€â”€ README.md              # DocumentaÃ§Ã£o principal
â”œâ”€â”€ configs/               # Arquivos de configuraÃ§Ã£o
â”‚   â”œâ”€â”€ config.yaml        # ConfiguraÃ§Ã£o principal
â”‚   â”œâ”€â”€ models/            # ConfiguraÃ§Ãµes de modelos
â”‚   â””â”€â”€ training/          # ConfiguraÃ§Ãµes de treinamento
â”œâ”€â”€ src/                   # CÃ³digo fonte principal
â”‚   â”œâ”€â”€ core/              # MÃ³dulos principais
â”‚   â”‚   â”œâ”€â”€ model_manager.py      # Gerenciamento de modelos
â”‚   â”‚   â”œâ”€â”€ dataset_manager.py    # Gerenciamento de datasets
â”‚   â”‚   â””â”€â”€ training_manager.py   # Gerenciamento de treinamento
â”‚   â”œâ”€â”€ ui/                # Interface do usuÃ¡rio
â”‚   â”‚   â”œâ”€â”€ components/    # Componentes reutilizÃ¡veis
â”‚   â”‚   â”‚   â””â”€â”€ sidebar.py # Barra lateral
â”‚   â”‚   â””â”€â”€ pages/         # PÃ¡ginas da aplicaÃ§Ã£o
â”‚   â”‚       â”œâ”€â”€ home.py           # Dashboard principal
â”‚   â”‚       â”œâ”€â”€ model_upload.py   # Upload de modelos
â”‚   â”‚       â”œâ”€â”€ dataset_upload.py # Upload de datasets
â”‚   â”‚       â”œâ”€â”€ training.py       # ConfiguraÃ§Ã£o de treino
â”‚   â”‚       â””â”€â”€ results.py        # Resultados e anÃ¡lise
â”‚   â””â”€â”€ utils/             # UtilitÃ¡rios
â”‚       â”œâ”€â”€ logging_utils.py      # Sistema de logging
â”‚       â””â”€â”€ file_utils.py         # UtilitÃ¡rios de arquivo
â”œâ”€â”€ data/                  # Dados da aplicaÃ§Ã£o
â”‚   â”œâ”€â”€ models/            # Modelos armazenados
â”‚   â”œâ”€â”€ datasets/          # Datasets carregados
â”‚   â””â”€â”€ outputs/           # Resultados de treinamento
â”œâ”€â”€ logs/                  # Logs do sistema
â””â”€â”€ tests/                 # Testes automatizados
```

### Tecnologias Utilizadas

#### Frontend
- **Streamlit 1.45+**: Framework principal para interface web
- **Plotly 6.1+**: VisualizaÃ§Ãµes interativas e grÃ¡ficos
- **Pandas 2.3+**: ManipulaÃ§Ã£o e anÃ¡lise de dados
- **NumPy 2.3+**: ComputaÃ§Ã£o numÃ©rica

#### Backend e ML
- **PyTorch 2.7+**: Framework de deep learning
- **Transformers 4.52+**: Biblioteca HuggingFace para LLMs
- **PEFT 0.15+**: Parameter-Efficient Fine-Tuning
- **Accelerate 1.7+**: OtimizaÃ§Ã£o de treinamento
- **Datasets 3.6+**: Carregamento e processamento de dados

#### Infraestrutura
- **Python 3.11**: Linguagem principal
- **YAML**: ConfiguraÃ§Ãµes estruturadas
- **Docker**: ContainerizaÃ§Ã£o
- **Git**: Controle de versÃ£o

### PadrÃµes de Design

#### Arquitetura MVC
- **Model**: Gerenciadores de dados (modelos, datasets, treinamento)
- **View**: Interface Streamlit (pÃ¡ginas e componentes)
- **Controller**: LÃ³gica de negÃ³cio e coordenaÃ§Ã£o

#### PrincÃ­pios SOLID
- **Single Responsibility**: Cada mÃ³dulo tem uma responsabilidade especÃ­fica
- **Open/Closed**: ExtensÃ­vel para novos tipos de modelos e datasets
- **Liskov Substitution**: Interfaces consistentes entre componentes
- **Interface Segregation**: Interfaces especÃ­ficas e focadas
- **Dependency Inversion**: DependÃªncias abstraÃ­das e injetÃ¡veis

#### PadrÃµes Utilizados
- **Factory Pattern**: CriaÃ§Ã£o de modelos e datasets
- **Observer Pattern**: Monitoramento de progresso de treinamento
- **Strategy Pattern**: Diferentes estratÃ©gias de fine-tuning
- **Singleton Pattern**: ConfiguraÃ§Ãµes globais

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

```bash
# ConfiguraÃ§Ãµes de GPU
CUDA_VISIBLE_DEVICES=0,1,2,3
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# ConfiguraÃ§Ãµes de HuggingFace
HF_TOKEN=seu_token_aqui
HF_HOME=/path/to/hf/cache

# ConfiguraÃ§Ãµes de logging
LOG_LEVEL=INFO
LOG_FILE=/path/to/logs/neuraltrain.log

# ConfiguraÃ§Ãµes de armazenamento
DATA_DIR=/path/to/data
MODELS_DIR=/path/to/models
OUTPUTS_DIR=/path/to/outputs
```

### ConfiguraÃ§Ã£o YAML

```yaml
# configs/config.yaml
app:
  name: "NeuralTrain Forge"
  version: "1.0.0"
  debug: false

server:
  host: "0.0.0.0"
  port: 8501
  max_upload_size: 200  # MB

training:
  default_batch_size: 4
  default_learning_rate: 2e-4
  default_epochs: 3
  checkpoint_dir: "./checkpoints"
  logs_dir: "./logs"

models:
  cache_dir: "./data/models"
  supported_formats: [".gguf", ".bin", ".safetensors", ".pt"]
  max_size_gb: 50

datasets:
  cache_dir: "./data/datasets"
  supported_formats: [".txt", ".jsonl", ".csv", ".parquet"]
  max_size_gb: 10
  train_split: 0.8
  validation_split: 0.2
```

### ConfiguraÃ§Ã£o Docker

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Instalar dependÃªncias do sistema
RUN apt-get update && apt-get install -y \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copiar arquivos de dependÃªncias
COPY requirements.txt .

# Instalar dependÃªncias Python
RUN pip install --no-cache-dir -r requirements.txt

# Copiar cÃ³digo fonte
COPY . .

# Expor porta
EXPOSE 8501

# Comando de inicializaÃ§Ã£o
CMD ["streamlit", "run", "main.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

## ğŸš€ Deployment

### Deployment Local

```bash
# Desenvolvimento
streamlit run main.py

# ProduÃ§Ã£o local
streamlit run main.py --server.port=8501 --server.address=0.0.0.0
```

### Deployment com Docker

```bash
# Build da imagem
docker build -t neuraltrain-forge .

# ExecuÃ§Ã£o do container
docker run -p 8501:8501 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --gpus all \
  neuraltrain-forge
```

### Deployment em Cloud

#### Paperspace Gradient

```python
# gradient_deploy.py
from gradient import sdk_client

client = sdk_client.SdkClient()

deployment = client.deployments.create(
    name="neuraltrain-forge",
    project_id="your-project-id",
    spec={
        "image": "neuraltrain-forge:latest",
        "port": 8501,
        "resources": {
            "replicas": 1,
            "instance_type": "P4000"
        }
    }
)
```

#### RunPod

```yaml
# runpod-config.yaml
apiVersion: v1
kind: Pod
metadata:
  name: neuraltrain-forge
spec:
  containers:
  - name: app
    image: neuraltrain-forge:latest
    ports:
    - containerPort: 8501
    resources:
      limits:
        nvidia.com/gpu: 1
      requests:
        memory: "8Gi"
        cpu: "4"
```

## ğŸ“Š Monitoramento e Logging

### Sistema de Logging

O NeuralTrain Forge implementa um sistema de logging estruturado e abrangente:

```python
# Exemplo de configuraÃ§Ã£o de logging
import logging
from src.utils.logging_utils import setup_logger

# Logger principal
logger = setup_logger(
    name="neuraltrain",
    level=logging.INFO,
    file_path="./logs/neuraltrain.log",
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

# Logging de treinamento
training_logger = setup_logger(
    name="training",
    level=logging.DEBUG,
    file_path="./logs/training.log"
)
```

### MÃ©tricas de Sistema

- **Uso de GPU**: Monitoramento de VRAM e utilizaÃ§Ã£o
- **Uso de CPU**: Monitoramento de processamento
- **Uso de RAM**: Monitoramento de memÃ³ria
- **Uso de Disco**: Monitoramento de armazenamento
- **Rede**: Monitoramento de transferÃªncia de dados

### IntegraÃ§Ã£o com TensorBoard

```python
# ConfiguraÃ§Ã£o TensorBoard
from torch.utils.tensorboard import SummaryWriter

writer = SummaryWriter(log_dir="./logs/tensorboard")

# Durante o treinamento
writer.add_scalar("Loss/Train", train_loss, epoch)
writer.add_scalar("Loss/Validation", val_loss, epoch)
writer.add_scalar("Learning_Rate", lr, epoch)
```

## ğŸ§ª Testes

### Estrutura de Testes

```
tests/
â”œâ”€â”€ unit/                  # Testes unitÃ¡rios
â”‚   â”œâ”€â”€ test_model_manager.py
â”‚   â”œâ”€â”€ test_dataset_manager.py
â”‚   â””â”€â”€ test_training_manager.py
â”œâ”€â”€ integration/           # Testes de integraÃ§Ã£o
â”‚   â”œâ”€â”€ test_upload_flow.py
â”‚   â””â”€â”€ test_training_flow.py
â”œâ”€â”€ e2e/                   # Testes end-to-end
â”‚   â””â”€â”€ test_complete_workflow.py
â””â”€â”€ fixtures/              # Dados de teste
    â”œâ”€â”€ sample_model.gguf
    â””â”€â”€ sample_dataset.jsonl
```

### Executando Testes

```bash
# Todos os testes
pytest tests/

# Testes especÃ­ficos
pytest tests/unit/test_model_manager.py

# Com cobertura
pytest --cov=src tests/

# Testes de integraÃ§Ã£o
pytest tests/integration/ -v
```

## ğŸ”’ SeguranÃ§a

### PrÃ¡ticas de SeguranÃ§a

- **ValidaÃ§Ã£o de Entrada**: Todos os uploads sÃ£o validados
- **SanitizaÃ§Ã£o**: Limpeza de dados de entrada
- **AutenticaÃ§Ã£o**: Suporte a tokens HuggingFace
- **AutorizaÃ§Ã£o**: Controle de acesso a recursos
- **Criptografia**: Dados sensÃ­veis criptografados
- **Auditoria**: Log de todas as aÃ§Ãµes importantes

### ConfiguraÃ§Ãµes de SeguranÃ§a

```python
# ConfiguraÃ§Ãµes de seguranÃ§a
SECURITY_CONFIG = {
    "max_upload_size": 200 * 1024 * 1024,  # 200MB
    "allowed_extensions": [".gguf", ".bin", ".safetensors"],
    "scan_uploads": True,
    "rate_limiting": {
        "enabled": True,
        "requests_per_minute": 60
    },
    "authentication": {
        "required": False,
        "providers": ["huggingface"]
    }
}
```

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir

1. **Fork** o repositÃ³rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. **Commit** suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. **Push** para a branch (`git push origin feature/AmazingFeature`)
5. **Abra** um Pull Request

### Diretrizes de ContribuiÃ§Ã£o

- Siga o padrÃ£o de cÃ³digo existente
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o quando necessÃ¡rio
- Use mensagens de commit descritivas
- Mantenha PRs focados e pequenos

### CÃ³digo de Conduta

Este projeto adere ao [Contributor Covenant](https://www.contributor-covenant.org/). Ao participar, vocÃª deve seguir este cÃ³digo.

## ğŸ“ Changelog

### v1.0.0 (2024-06-11)

#### âœ¨ Funcionalidades
- Interface web completa com Streamlit
- Sistema de upload de modelos (local e HuggingFace)
- Sistema de upload de datasets (mÃºltiplos formatos)
- ConfiguraÃ§Ã£o completa de fine-tuning com LoRA/QLoRA
- Dashboard com mÃ©tricas e visualizaÃ§Ãµes
- Sistema de resultados e anÃ¡lise
- Monitoramento em tempo real
- ExportaÃ§Ã£o de modelos e relatÃ³rios

#### ğŸ—ï¸ Arquitetura
- Arquitetura modular e extensÃ­vel
- SeparaÃ§Ã£o clara de responsabilidades
- Sistema de logging estruturado
- ConfiguraÃ§Ã£o via YAML
- Suporte a Docker

#### ğŸ”§ Tecnologias
- Python 3.11+
- Streamlit 1.45+
- PyTorch 2.7+
- Transformers 4.52+
- PEFT 0.15+
- Plotly 6.1+

## ğŸ†˜ Suporte

### DocumentaÃ§Ã£o

- [DocumentaÃ§Ã£o Completa](docs/)
- [Guia de InstalaÃ§Ã£o](docs/installation.md)
- [Tutorial de Uso](docs/tutorial.md)
- [API Reference](docs/api.md)
- [FAQ](docs/faq.md)

### Comunidade

- [GitHub Issues](https://github.com/seu-usuario/neuraltrain-forge/issues)
- [Discussions](https://github.com/seu-usuario/neuraltrain-forge/discussions)
- [Discord](https://discord.gg/neuraltrain)
- [Twitter](https://twitter.com/neuraltrain)

### Suporte Comercial

Para suporte comercial, treinamentos ou consultoria, entre em contato:
- Email: support@neuraltrain.com
- Website: https://neuraltrain.com

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- [HuggingFace](https://huggingface.co/) pela biblioteca Transformers e PEFT
- [Streamlit](https://streamlit.io/) pelo framework de interface web
- [PyTorch](https://pytorch.org/) pelo framework de deep learning
- [Plotly](https://plotly.com/) pelas visualizaÃ§Ãµes interativas
- Comunidade open source por todas as contribuiÃ§Ãµes

---

<div align="center">

**NeuralTrain Forge** - Democratizando o Fine-tuning de LLMs

[![GitHub stars](https://img.shields.io/github/stars/seu-usuario/neuraltrain-forge?style=social)](https://github.com/seu-usuario/neuraltrain-forge/stargazers)
[![GitHub forks](https://img.shields.io/github/forks/seu-usuario/neuraltrain-forge?style=social)](https://github.com/seu-usuario/neuraltrain-forge/network/members)
[![GitHub issues](https://img.shields.io/github/issues/seu-usuario/neuraltrain-forge)](https://github.com/seu-usuario/neuraltrain-forge/issues)

</div>

