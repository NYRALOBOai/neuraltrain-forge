version: '3.8'

services:
  neuraltrain-forge:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: neuraltrain-forge
    ports:
      - "8501:8501"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./checkpoints:/app/checkpoints
      - ./configs:/app/configs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - HF_HOME=/app/cache/huggingface
      - LOG_LEVEL=INFO
      - LOG_FILE=/app/logs/neuraltrain.log
      - DATA_DIR=/app/data
      - MODELS_DIR=/app/data/models
      - DATASETS_DIR=/app/data/datasets
      - OUTPUTS_DIR=/app/data/outputs
      - STREAMLIT_SERVER_PORT=8501
      - STREAMLIT_SERVER_ADDRESS=0.0.0.0
      - STREAMLIT_BROWSER_GATHER_USAGE_STATS=false
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Serviço opcional para TensorBoard
  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: neuraltrain-tensorboard
    ports:
      - "6006:6006"
    volumes:
      - ./logs/tensorboard:/logs
    command: tensorboard --logdir=/logs --host=0.0.0.0 --port=6006
    restart: unless-stopped
    profiles:
      - tensorboard

  # Serviço opcional para Jupyter Notebook
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    container_name: neuraltrain-jupyter
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data
      - ./src:/app/src
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - JUPYTER_TOKEN=neuraltrain
    command: jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root
    restart: unless-stopped
    profiles:
      - jupyter

networks:
  default:
    name: neuraltrain-network

