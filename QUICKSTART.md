# ğŸš€ Guia de InÃ­cio RÃ¡pido - NeuralTrain Forge

Este guia irÃ¡ ajudÃ¡-lo a configurar e executar o NeuralTrain Forge em poucos minutos.

## âš¡ InstalaÃ§Ã£o RÃ¡pida (Recomendada)

### 1. Clone o RepositÃ³rio
```bash
git clone https://github.com/seu-usuario/neuraltrain-forge.git
cd neuraltrain-forge
```

### 2. Execute o Script de InstalaÃ§Ã£o
```bash
chmod +x install.sh
./install.sh
```

O script irÃ¡:
- âœ… Verificar dependÃªncias do sistema
- âœ… Criar ambiente virtual Python
- âœ… Instalar todas as dependÃªncias
- âœ… Configurar estrutura de diretÃ³rios
- âœ… Testar a instalaÃ§Ã£o

### 3. Inicie a AplicaÃ§Ã£o
```bash
./start.sh
```

### 4. Acesse no Navegador
Abra seu navegador e vÃ¡ para: **http://localhost:8501**

---

## ğŸ› ï¸ InstalaÃ§Ã£o Manual

Se preferir instalar manualmente ou o script automÃ¡tico nÃ£o funcionar:

### PrÃ©-requisitos
- Python 3.10 ou superior
- pip (gerenciador de pacotes Python)
- Git

### Passos

1. **Clone e entre no diretÃ³rio:**
```bash
git clone https://github.com/seu-usuario/neuraltrain-forge.git
cd neuraltrain-forge
```

2. **Crie ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Instale dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Configure ambiente:**
```bash
cp .env.example .env
# Edite o arquivo .env conforme necessÃ¡rio
```

5. **Execute a aplicaÃ§Ã£o:**
```bash
streamlit run main.py
```

---

## ğŸ³ Usando Docker

### OpÃ§Ã£o 1: Docker Compose (Recomendada)
```bash
# Construir e executar
docker-compose up --build

# Executar em background
docker-compose up -d

# Parar
docker-compose down
```

### OpÃ§Ã£o 2: Docker Manual
```bash
# Construir imagem
docker build -t neuraltrain-forge .

# Executar container
docker run -p 8501:8501 \
  -v $(pwd)/data:/app/data \
  -v $(pwd)/logs:/app/logs \
  --gpus all \
  neuraltrain-forge
```

---

## ğŸ¯ Primeiro Uso

### 1. Acesse o Dashboard
- Abra http://localhost:8501
- VocÃª verÃ¡ o dashboard principal com mÃ©tricas do sistema

### 2. Carregue um Modelo
- VÃ¡ para **"ğŸ“¤ Upload de Modelos"**
- Escolha entre:
  - **Upload Local**: Carregue um arquivo .gguf, .bin ou .safetensors
  - **HuggingFace Hub**: Baixe diretamente do HuggingFace

### 3. Carregue um Dataset
- VÃ¡ para **"ğŸ“Š Upload de Datasets"**
- Carregue um arquivo .txt, .jsonl, .csv ou .parquet
- O sistema irÃ¡ validar e processar automaticamente

### 4. Configure o Treinamento
- VÃ¡ para **"âš™ï¸ ConfiguraÃ§Ã£o de Treino"**
- Preencha:
  - Nome do job
  - Selecione modelo e dataset
  - Configure parÃ¢metros LoRA/QLoRA
  - Ajuste hiperparÃ¢metros

### 5. Inicie o Treinamento
- Clique em **"ğŸš€ Iniciar Treinamento"**
- Monitore o progresso em tempo real
- Veja mÃ©tricas e grÃ¡ficos atualizados

### 6. Analise os Resultados
- VÃ¡ para **"ğŸ“ˆ Resultados"**
- Visualize grÃ¡ficos de loss e mÃ©tricas
- Baixe o modelo treinado
- Exporte relatÃ³rios

---

## ğŸ“‹ Exemplos PrÃ¡ticos

### Exemplo 1: Fine-tuning de Modelo de Chat

1. **Modelo**: LLaMA-7B-Chat (do HuggingFace)
2. **Dataset**: ConversaÃ§Ãµes em formato JSONL
3. **ConfiguraÃ§Ã£o**:
   - Tipo: LoRA
   - Rank: 16
   - Alpha: 32
   - Learning Rate: 2e-4
   - Ã‰pocas: 3

### Exemplo 2: Fine-tuning para Tarefa EspecÃ­fica

1. **Modelo**: Mistral-7B-Instruct
2. **Dataset**: Dados de instruÃ§Ã£o em CSV
3. **ConfiguraÃ§Ã£o**:
   - Tipo: QLoRA
   - Rank: 8
   - Alpha: 16
   - Learning Rate: 1e-4
   - Ã‰pocas: 5

---

## ğŸ”§ ConfiguraÃ§Ãµes Importantes

### GPU
Se vocÃª tem GPU NVIDIA:
```bash
# Verificar se CUDA estÃ¡ disponÃ­vel
nvidia-smi

# Configurar no .env
CUDA_VISIBLE_DEVICES=0
```

### HuggingFace Token
Para modelos privados:
```bash
# No arquivo .env
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### Limites de MemÃ³ria
Para evitar problemas de memÃ³ria:
```bash
# No arquivo .env
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

---

## ğŸš¨ SoluÃ§Ã£o de Problemas Comuns

### Erro: "Port 8501 is already in use"
```bash
# Encontrar processo usando a porta
lsof -i :8501

# Matar processo
kill -9 <PID>

# Ou usar porta diferente
streamlit run main.py --server.port 8502
```

### Erro: "CUDA out of memory"
- Reduza o batch size
- Habilite gradient checkpointing
- Use QLoRA em vez de LoRA
- Reduza max_length

### Erro: "Module not found"
```bash
# Reativar ambiente virtual
source venv/bin/activate

# Reinstalar dependÃªncias
pip install -r requirements.txt
```

### Upload falha
- Verifique tamanho do arquivo (limite: 200MB)
- Verifique formato suportado
- Verifique espaÃ§o em disco

---

## ğŸ“š PrÃ³ximos Passos

1. **Leia a documentaÃ§Ã£o completa**: [README.md](README.md)
2. **Explore exemplos avanÃ§ados**: [docs/examples/](docs/examples/)
3. **Configure para produÃ§Ã£o**: [docs/deployment.md](docs/deployment.md)
4. **Contribua para o projeto**: [CONTRIBUTING.md](CONTRIBUTING.md)

---

## ğŸ†˜ Precisa de Ajuda?

- ğŸ“– **DocumentaÃ§Ã£o**: [README.md](README.md)
- ğŸ› **Reportar Bug**: [GitHub Issues](https://github.com/seu-usuario/neuraltrain-forge/issues)
- ğŸ’¬ **DiscussÃµes**: [GitHub Discussions](https://github.com/seu-usuario/neuraltrain-forge/discussions)
- ğŸ“§ **Email**: support@neuraltrain.com

---

## âœ… Checklist de VerificaÃ§Ã£o

Antes de comeÃ§ar, certifique-se de que:

- [ ] Python 3.10+ estÃ¡ instalado
- [ ] Git estÃ¡ instalado
- [ ] VocÃª tem pelo menos 8GB de RAM
- [ ] VocÃª tem pelo menos 50GB de espaÃ§o livre
- [ ] (Opcional) GPU NVIDIA com drivers CUDA
- [ ] ConexÃ£o com internet para downloads

---

**ğŸ‰ Pronto! VocÃª estÃ¡ preparado para usar o NeuralTrain Forge!**

Divirta-se explorando o fine-tuning de modelos de linguagem! ğŸ§ âœ¨

